#! /usr/bin/env python

import argparse
import logging, time
import h5py
import numpy as np
from pycbc import waveform
from pycbc.types import zeros, float32, complex64
from chisqnet.filtering import ChisqFilter
import tensorflow as tf
import tensorflow_probability as tfp
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from chisqnet.training_utils import SampleFile, chi2, nc_chi2


def abs_loss(snr_prime, snr, injs):
    snr_prime_thresh = tf.maximum(snr_prime, tf.ones_like(snr_prime) * 4.)

    trig_loss = snr_prime_thresh - 4.
    inj_loss = snr - snr_prime

    batch_loss = tf.where(injs, inj_loss, trig_loss)
    return batch_loss


def sqr_loss(snr_prime, snr, injs):
    snr_prime_thresh = tf.maximum(snr_prime, tf.ones_like(snr_prime) * 4.)

    trig_loss = (snr_prime_thresh - 4.) ** 2.
    inj_loss = (snr - snr_prime) ** 2.

    batch_loss = tf.where(injs, inj_loss, trig_loss)
    return batch_loss


parser = argparse.ArgumentParser()

# Gather inputs
parser.add_argument("--training-sample-file", required=True,
                    help="Sample file to be used in training")
parser.add_argument("--validation-sample-file",
                    help="Sample file to be used in training")
parser.add_argument("--checkpoint-file",
                    help="Checkpoint file with the latest state of the "
                         "model to be loaded")

# Gather arguments for filtering/bank
parser.add_argument("--bank-file", required=True,
                    help="The bank file to be used to generate templates")
parser.add_argument("--low-frequency-cutoff", type=float,
                  help="The low frequency cutoff to use for filtering (Hz)")
parser.add_argument("--enable-bank-start-frequency", action='store_true',
                  help="Read the starting frequency of template waveforms"
                       " from the template bank.")
parser.add_argument("--max-template-length", type=float,
                  help="The maximum length of a template is seconds. The "
                       "starting frequency of the template is modified to "
                       "ensure the proper length")
waveform.bank.add_approximant_arg(parser)
parser.add_argument("--order", type=int,
                  help="The integer half-PN order at which to generate"
                       " the approximant. Default is -1 which indicates to use"
                       " approximant defined default.", default=-1,
                       choices = np.arange(-1, 9, 1))
taper_choices = ["start","end","startend"]
parser.add_argument("--taper-template", choices=taper_choices,
                    help="For time-domain approximants, taper the start and/or"
                         " end of the waveform before FFTing.")

# Gather arguments for training
parser.add_argument("--batch-size", required=True, type=int,
                    help="The number of samples to analyse in one batch")
parser.add_argument("--epochs", required=True, type=int,
                     help="The number of times to analyse the full dataset")
parser.add_argument("--batches-per-step", type=int,
                    help="The number of batches to run before running validation")
parser.add_argument("--shuffle", action="store_true",
                    help="If given, shuffle the order of analysed segments each epoch")
parser.add_argument("--snr-cut-width", default=0.1, type=float,
                    help="The width around each trigger to cut from the SNR timeseries")
parser.add_argument("--loss-function", default="absolute",
                    help="The type of loss to be used.")
parser.add_argument("--learning-rate", default=0.001, type=float,
                    help="The learning rate passed to the training optimizer")
parser.add_argument("--learning-rate-decay", default=1., type=float,
                    help="The value to multiply the learning rate by after each step")

# Gather arguments for transform
parser.add_argument("--config-file", required=True,
                    help="The config gile used to create the transformation")

# Gather inputs for output
parser.add_argument("--output-file", required=True,
                    help="The path of the output file to save the weights and losses")
parser.add_argument("--checkpoint", type=int, default=1,
                    help="If given save the weights after this many epochs")

# Gather additional options
parser.add_argument("--verbose", action='store_true')

args = parser.parse_args()

if args.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARNING
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

training_samples = SampleFile(args.training_sample_file)
if args.validation_sample_file:
    validation_samples = SampleFile(args.validation_sample_file)

template_mem = zeros(training_samples.tlen, dtype=complex64)

if args.enable_bank_start_frequency:
    low_frequency_cutoff = None
else:
    low_frequency_cutoff = args.low_frequency_cutoff

bank = waveform.FilterBank(
    args.bank_file, training_samples.flen, training_samples.delta_f,
    low_frequency_cutoff=low_frequency_cutoff,
    dtype=complex64, phase_order=args.order,
    taper=args.taper_template, approximant=args.approximant,
    out=template_mem, max_template_length=args.max_template_length
)

freqs = np.arange(training_samples.flen) * training_samples.delta_f

if args.checkpoint_file is None:
    epoch = 0
    chisq_transform = ChisqFilter.from_config(
        args.config_file,
        freqs, training_samples.flow,
        training_samples.sample_rate // 2
    )
else:
    with h5py.File(args.checkpoint_file, 'r') as f:
        epoch = f.attrs['epoch']
        g = f['optimizer_epoch_{0}'.format(epoch)]
        opt_weights = [g['weight_{0}'.format(i)][()]
                       for i in range(g.attrs['weights_num'])]

    chisq_transform = ChisqFilter.from_file(
        args.checkpoint_file,
        freqs, training_samples.flow,
        training_samples.sample_rate // 2,
        group="model_epoch_{0}".format(epoch)
    )

train = chisq_transform.trainable_weights
trainable_names = [k for k in train.keys()]
trainable_names.sort()
trainable_weights = [train[k] for k in trainable_names]

loss_fns = {'absolute': abs_loss,
            'squared': sqr_loss}
loss_fn = loss_fns[args.loss_function]

optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate)

if args.checkpoint_file is not None:
    grads = [tf.zeros_like(w) for w in trainable_weights]
    optimizer.apply_gradients(zip(grads, trainable_weights))
    optimizer.set_weights(opt_weights)

nbatches = int(np.ceil(1. * training_samples.num / args.batch_size))
nbatch = epoch * nbatches

output_file_created = False

for i in range(args.epochs):

    logging.info("Starting epoch")
    logging.info("Starting training")

    order = np.arange(training_samples.num)
    if args.shuffle:
        np.random.shuffle(order)
    
    losses = []
    batches = []

    inj_losses = []
    inj_count = []
    inj_epoch = 0

    trig_losses = []
    trig_count = []
    trig_epoch = 0

    snr_removed = []

    times = 0.

    val_losses = []
    val_batches = []

    val_inj_losses = []
    val_trig_losses = []

    val_snr_removeds = []

    for j in range(nbatches):

        nstep = nbatch // args.batches_per_step
        optimizer.learning_rate = args.learning_rate * args.learning_rate_decay ** (nstep)

        lidx = int(1. * j * training_samples.num / nbatches)
        hidx = int(1. * (j + 1) * training_samples.num / nbatches)

        idxs = order[lidx:hidx]
        idxs = np.sort(idxs)

        logging.info("Starting batch")

        start = time.time()

        segs, psds, temp, injs, gather_idxs, params = \
            training_samples.get_tensors(idxs, bank)

        logging.info("Batch inputs read")

        with tf.GradientTape() as tape:

            snr_prime, snr = chisq_transform.get_max_snr_prime(
                temp, segs, psds, params,
                gather_idxs=gather_idxs,
                max_snr=True, training=True
            )

            batch_loss = loss_fn(snr_prime, snr, injs)
            loss = tf.reduce_mean(batch_loss)

            loss += chisq_transform.get_regulariser_loss()
            logging.info("Loss calculated")

        gradients = tape.gradient(loss, trainable_weights, unconnected_gradients='none')
        logging.info("Gradients calculated")

        optimizer.apply_gradients(zip(gradients, trainable_weights))
        logging.info("Gradients applied")
        logging.info("Completed batch")

        losses += [loss]
        batches += [nbatch]

        inj_lgc = injs.numpy()
        trig_lgc = np.logical_not(inj_lgc)

        inj_count += [np.sum(inj_lgc)]
        trig_count += [np.sum(trig_lgc)]

        inj_epoch += np.sum(inj_lgc)
        trig_epoch += np.sum(trig_lgc)

        inj_losses += [np.sum(batch_loss.numpy()[inj_lgc])]
        trig_losses += [np.sum(batch_loss.numpy()[trig_lgc])]

        snr_prime_thresh = tf.maximum(snr_prime, tf.ones_like(snr_prime) * 4.)
        snr_thresh = tf.maximum(snr, tf.ones_like(snr) * 4.)
        snr_removed += [np.sum(1 - ((snr_prime_thresh - 4.) / (snr_thresh - 4.)).numpy()[trig_lgc])]

        times += time.time() - start

        nbatch += 1

        if j == (nbatches - 1) or (nbatch % args.batches_per_step) == 0:
            end_str = '\n'
        else:
            end_str = '\r'

        print("Epoch: {0:3d}/{1:3d} ".format(i + 1, args.epochs)
              + "Batch: {0:4d}/{1:4d}, ".format(j + 1, nbatches)
              + "Av. Loss: {0:3.4f}, ".format(np.sum(losses) / (j + 1))
              + "Av. Inj Loss: {0:3.4f}, ".format(np.sum(inj_losses) / max(np.sum(inj_count), 1))
              + "Av. Trig Loss: {0:3.4f}, ".format(np.sum(trig_losses) / max(np.sum(trig_count), 1))
              + "Av. Trig SNR Frac Removed: {0:1.4f}, ".format(np.sum(snr_removed) / max(np.sum(trig_count), 1))
              + "Av. Time: {0:6.2f}".format(times / (j + 1)),
              end=end_str)

        if (args.validation_sample_file is None) \
                or ((nbatch % args.batches_per_step) != 0 and (j + 1) != nbatches):
            continue

        logging.info("Starting validation")
        val_order = np.arange(validation_samples.num)
        val_nbatches = int(np.ceil(1. * validation_samples.num / args.batch_size))

        val_loss = 0.

        val_inj_count = 0
        val_trig_count = 0

        val_inj_loss = 0.
        val_trig_loss = 0.

        val_snr_removed = 0.

        val_times = 0.

        for k in range(val_nbatches):

            lidx = int(1. * k * validation_samples.num / val_nbatches)
            hidx = int(1. * (k + 1) * validation_samples.num / val_nbatches)

            idxs = order[lidx:hidx]
            idxs = np.sort(idxs)

            logging.info("Starting batch")

            start = time.time()

            segs, psds, temp, injs, gather_idxs, params = \
                validation_samples.get_tensors(idxs, bank)

            logging.info("Batch inputs read")

            snr_prime, snr = chisq_transform.get_max_snr_prime(
                temp, segs, psds, params,
                gather_idxs=gather_idxs,
                max_snr=True, training=False
            )

            batch_loss = loss_fn(snr_prime, snr, injs)
            val_loss += tf.reduce_sum(batch_loss)

            logging.info("Loss calculated")
            logging.info("Completed batch")

            inj_lgc = injs.numpy()
            trig_lgc = np.logical_not(inj_lgc)

            val_inj_count += np.sum(inj_lgc)
            val_trig_count += np.sum(trig_lgc)
            total_count = val_inj_count + val_trig_count

            val_inj_loss += np.sum(batch_loss.numpy()[inj_lgc])
            val_trig_loss += np.sum(batch_loss.numpy()[trig_lgc])

            snr_prime_thresh = tf.maximum(snr_prime, tf.ones_like(snr_prime) * 4.)
            snr_thresh = tf.maximum(snr, tf.ones_like(snr) * 4.)
            val_snr_removed += np.sum(1 - ((snr_prime_thresh - 4.) / (snr_thresh - 4.)).numpy()[trig_lgc])

            val_times += time.time() - start

            if k == (val_nbatches - 1):
                end_str = '\n'
            else:
                end_str = '\r'
                
            print("Batch: {0:4d}/{1:4d}, ".format(k + 1, val_nbatches)
                  + "Av. Loss: {0:3.4f}, ".format(val_loss / total_count)
                  + "Av. Inj Loss: {0:3.4f}, ".format(val_inj_loss / max(val_inj_count, 1))
                  + "Av. Trig Loss: {0:3.4f}, ".format(val_trig_loss / max(val_trig_count, 1))
                  + "Av. Trig SNR Frac Removed: {0:1.4f}, ".format(val_snr_removed / max(val_trig_count, 1))
                  + "Av. Time: {0:6.2f}".format(val_times / (k + 1)),
                  end=end_str)

        val_losses += [val_loss / total_count]
        val_batches += [nbatch]

        val_inj_losses += [val_inj_loss / val_inj_count]
        val_trig_losses += [val_trig_loss / val_trig_count]

        val_snr_removeds += [val_snr_removed / val_trig_count]

    if (i + 1) == args.epochs or (args.checkpoint and (i + 1) % args.checkpoint == 0):
        chisq_transform.to_file(
            args.output_file,
            group="model_epoch_{0}".format(epoch + i + 1),
            append=output_file_created
        )

        opt_weights = optimizer.get_weights()
        with h5py.File(args.output_file, 'a') as f:
            f.attrs['epoch'] = epoch + i + 1
            g = f.create_group('optimizer_epoch_{0}'.format(epoch + i + 1))
            g.attrs['weights_num'] = len(opt_weights)
            for j in range(len(opt_weights)):
                opt = opt_weights[j]
                _ = g.create_dataset('weight_{0}'.format(j), data=opt)

        output_file_created = True

    inj_losses = np.array(inj_losses) / np.maximum(np.array(inj_count), 1)
    trig_losses = np.array(trig_losses) / np.maximum(np.array(trig_count), 1)
    snr_removed = np.array(snr_removed) / np.maximum(np.array(trig_count), 1)

    with h5py.File(args.output_file, 'a') as f:
        _ = f.create_dataset('training_batch_epoch_{0}'.format(epoch + i + 1), data=np.array(batches))
        _ = f.create_dataset('training_loss_epoch_{0}'.format(epoch + i + 1), data=np.array(losses))
        _ = f.create_dataset('training_inj_loss_epoch_{0}'.format(epoch + i + 1), data=inj_losses)
        _ = f.create_dataset('training_trig_loss_epoch_{0}'.format(epoch + i + 1), data=trig_losses)
        _ = f.create_dataset('training_snr_removed_epoch_{0}'.format(epoch + i + 1), data=snr_removed)

        _ = f.create_dataset('validation_batch_epoch_{0}'.format(epoch + i + 1),
                             data=np.array(val_batches))
        _ = f.create_dataset('validation_loss_epoch_{0}'.format(epoch + i + 1),
                             data=np.array(val_losses))
        _ = f.create_dataset('validation_inj_loss_epoch_{0}'.format(epoch + i + 1),
                             data=np.array(val_inj_losses))
        _ = f.create_dataset('validation_trig_loss_epoch_{0}'.format(epoch + i + 1),
                             data=np.array(val_trig_losses))
        _ = f.create_dataset('validation_snr_removed_epoch_{0}'.format(epoch + i + 1),
                             data=np.array(val_snr_removeds))
