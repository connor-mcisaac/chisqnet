#! /usr/bin/env python

import argparse
import logging, time
import h5py
import numpy as np
from pycbc import waveform
from pycbc.types import zeros, float32, complex64
import tensorflow as tf
import tensorflow_probability as tfp
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt


parser = argparse.ArgumentParser()

# Gather inputs
parser.add_argument("--training-sample-file", required=True,
                    help="Sample file to be used in training")
parser.add_argument("--validation-sample-file",
                    help="Sample file to be used in training")

# Gather arguments for filtering/bank
parser.add_argument("--bank-file", required=True,
                    help="The bank file to be used to generate templates")
parser.add_argument("--low-frequency-cutoff", type=float,
                  help="The low frequency cutoff to use for filtering (Hz)")
parser.add_argument("--enable-bank-start-frequency", action='store_true',
                  help="Read the starting frequency of template waveforms"
                       " from the template bank.")
parser.add_argument("--max-template-length", type=float,
                  help="The maximum length of a template is seconds. The "
                       "starting frequency of the template is modified to "
                       "ensure the proper length")
waveform.bank.add_approximant_arg(parser)
parser.add_argument("--order", type=int,
                  help="The integer half-PN order at which to generate"
                       " the approximant. Default is -1 which indicates to use"
                       " approximant defined default.", default=-1,
                       choices = np.arange(-1, 9, 1))
taper_choices = ["start","end","startend"]
parser.add_argument("--taper-template", choices=taper_choices,
                    help="For time-domain approximants, taper the start and/or"
                         " end of the waveform before FFTing.")

# Gather arguments for training
parser.add_argument("--batch-size", required=True, type=int,
                    help="The number of samples to analyse in one batch")
parser.add_argument("--epochs", required=True, type=int,
                     help="The number of times to analyse the full dataset")
parser.add_argument("--batches-per-step", type=int,
                    help="The number of batches to run before running validation")
parser.add_argument("--shuffle", action="store_true",
                    help="If given, shuffle the order of analysed segments each epoch")
parser.add_argument("--snr-cut-width", default=0.1, type=float,
                    help="The width around each trigger to cut from the SNR timeseries")
parser.add_argument("--loss-function", default="absolute",
                    help="The type of loss to be used.")
parser.add_argument("--learning-rate", default=0.001, type=float,
                    help="The learning rate passed to the training optimizer")
parser.add_argument("--learning-rate-decay", default=1., type=float,
                    help="The value to multiply the learning rate by after each epoch")
parser.add_argument("--loss-snr-threshold", default=4., type=float,
                    help="The SNR below which trigger loss is 0")
parser.add_argument("--loss-keyword-args", nargs='+',
                    help="Keyword arguments for the loss function")
parser.add_argument("--optimizer", default="sgd",
                    help="The type of optimizer to be used.")
parser.add_argument("--optimizer-keyword-args", nargs='+', default=[],
                    help="Keyword arguments for the optimizer")

# Gather arguments for transform
parser.add_argument("--config-file", required=True,
                    help="The config file used to create the transformation")

# Gather inputs for output
parser.add_argument("--output-file", required=True,
                    help="The path of the output file to save the weights and losses")

# Gather additional options
parser.add_argument("--verbose", action='store_true')
parser.add_argument("--ncores", type=int, default=1)

args = parser.parse_args()

tf.config.threading.set_intra_op_parallelism_threads(args.ncores)
tf.config.threading.set_inter_op_parallelism_threads(args.ncores)


from chisqnet.filtering import ChisqFilter
from chisqnet.training_utils import SampleFile, chi2, nc_chi2
from chisqnet.loss import select_loss


def select_optimizer(args):
    optimizers = {
        "sgd": tf.keras.optimizers.SGD,
        "rmsprop": tf.keras.optimizers.RMSprop,
        "adam": tf.keras.optimizers.Adam
    }
    kwarg_strings = args.optimizer_keyword_args
    kwargs = {}
    for kwarg_str in kwarg_strings:
        k, v = kwarg_str.split(':')
        if v == "True":
            kwargs[k] = True
        elif v == "False":
            kwargs[k] = False
        else:
            kwargs[k] = float(v)
    return optimizers[args.optimizer](learning_rate=args.learning_rate, **kwargs)


if args.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARNING
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

training_samples = SampleFile(args.training_sample_file)
if args.validation_sample_file:
    validation_samples = SampleFile(args.validation_sample_file)

template_mem = zeros(training_samples.tlen, dtype=complex64)

if args.enable_bank_start_frequency:
    low_frequency_cutoff = None
else:
    low_frequency_cutoff = args.low_frequency_cutoff

bank = waveform.FilterBank(
    args.bank_file, training_samples.flen, training_samples.delta_f,
    low_frequency_cutoff=low_frequency_cutoff,
    dtype=complex64, phase_order=args.order,
    taper=args.taper_template, approximant=args.approximant,
    out=template_mem, max_template_length=args.max_template_length
)

freqs = np.arange(training_samples.flen) * training_samples.delta_f

chisq_transform = ChisqFilter.from_config(
    args.config_file,
    freqs, training_samples.flow,
    training_samples.sample_rate // 2
)

train = chisq_transform.trainable_weights
train = {k: v for k, v in train.items()
         if k in ['threshold', 'constant', 'alpha', 'beta']}

trainable_names = [k for k in train.keys()]
trainable_names.sort()
trainable_weights = [train[k] for k in trainable_names]

loss_fn = select_loss(args.loss_function).from_cli(args)

optimizer = select_optimizer(args)

nbatches = int(np.ceil(1. * training_samples.num / args.batch_size))
nbatch = 0

all_snrs = []
all_rchisqs = []
all_injs = []

val_snrs = []
val_rchisqs = []
val_injs = []

losses = []
batches = []

inj_losses = []
inj_count = []

trig_losses = []
trig_count = []

snr_removed = []
inj_removed = []

val_losses = []
val_batches = []

val_inj_losses = []
val_trig_losses = []

val_snr_removeds = []
val_inj_removeds = []

val_complete = False

for i in range(args.epochs):

    if i == 1:
        all_snrs = tf.concat(all_snrs, axis=0)
        all_rchisqs = tf.concat(all_rchisqs, axis=0)
        all_injs = tf.concat(all_injs, axis=0)

    logging.info("Starting epoch")
    logging.info("Starting training")

    order = np.arange(training_samples.num)
    if args.shuffle:
        np.random.shuffle(order)
    
    optimizer.learning_rate = args.learning_rate * args.learning_rate_decay ** i

    for j in range(nbatches):

        lidx = int(1. * j * training_samples.num / nbatches)
        hidx = int(1. * (j + 1) * training_samples.num / nbatches)

        idxs = order[lidx:hidx]
        idxs = np.sort(idxs)

        logging.info("Starting batch")

        if i == 0:
            segs, psds, temp, injs, gather_idxs, params = \
                training_samples.get_tensors(idxs, bank, cuts=True)

            logging.info("Batch inputs read")

            with tf.GradientTape() as tape:

                snr_prime, snr, rchisq = chisq_transform.get_max_snr_prime(
                    temp, segs, psds, params, gather_idxs=gather_idxs,
                    max_snr=True, training=True
                )

                batch_loss = loss_fn(snr_prime, snr, injs, training=True)
                loss = tf.reduce_mean(batch_loss)

                loss += chisq_transform.get_regulariser_loss()
                logging.info("Loss calculated")

            all_snrs += [snr]
            all_rchisqs += [rchisq]
            all_injs += [injs]

        else:
            idxs = tf.convert_to_tensor(idxs)
            snr = tf.gather(all_snrs, idxs)
            rchisq = tf.gather(all_rchisqs, idxs)
            injs = tf.gather(all_injs, idxs)

            with tf.GradientTape() as tape:

                snr_prime = chisq_transform.get_snr_prime(snr, rchisq, training=True)

                batch_loss = loss_fn(snr_prime, snr, injs, training=True)
                loss = tf.reduce_mean(batch_loss)

                loss += chisq_transform.get_regulariser_loss()
                logging.info("Loss calculated")

        gradients = tape.gradient(loss, trainable_weights, unconnected_gradients='none')
        logging.info("Gradients calculated")

        optimizer.apply_gradients(zip(gradients, trainable_weights))
        logging.info("Gradients applied")
        logging.info("Completed batch")

        losses += [loss]
        batches += [nbatch]

        inj_lgc = injs.numpy()
        trig_lgc = np.logical_not(inj_lgc)

        inj_count += [np.sum(inj_lgc)]
        trig_count += [np.sum(trig_lgc)]

        inj_losses += [np.sum(batch_loss.numpy()[inj_lgc])]
        trig_losses += [np.sum(batch_loss.numpy()[trig_lgc])]

        snr_removed += [np.sum(1 - (snr_prime / snr).numpy()[trig_lgc])]
        inj_removed += [np.sum(1 - (snr_prime / snr).numpy()[inj_lgc])]

        nbatch += 1

        if j == (nbatches - 1) or (nbatch % args.batches_per_step) == 0:
            end_str = '\n'
        else:
            end_str = '\r'

        print("Epoch: {0:3d}/{1:3d} ".format(i + 1, args.epochs)
              + "Batch: {0:4d}/{1:4d}, ".format(j + 1, nbatches)
              + "Av. Loss: {0:3.4f}, ".format(np.sum(losses) / (j + 1))
              + "Av. Inj Loss: {0:3.4f}, ".format(np.sum(inj_losses) / max(np.sum(inj_count), 1))
              + "Av. Trig Loss: {0:3.4f}, ".format(np.sum(trig_losses) / max(np.sum(trig_count), 1)),
              end=end_str)

        if (args.validation_sample_file is None) \
                or ((nbatch % args.batches_per_step) != 0 and (j + 1) != nbatches):
            continue

        logging.info("Starting validation")
        val_order = np.arange(validation_samples.num)
        val_nbatches = int(np.ceil(1. * validation_samples.num / args.batch_size))

        val_loss = 0.

        val_inj_count = 0
        val_trig_count = 0

        val_inj_loss = 0.
        val_trig_loss = 0.

        val_snr_removed = 0.
        val_inj_removed = 0.

        val_trig_snr_primes = []
        val_trig_snrs = []
        val_trig_rchisq = []
        val_inj_snr_primes = []
        val_inj_snrs = []
        val_inj_rchisq = []

        for k in range(val_nbatches):

            lidx = int(1. * k * validation_samples.num / val_nbatches)
            hidx = int(1. * (k + 1) * validation_samples.num / val_nbatches)
            idxs = np.arange(lidx, hidx)

            logging.info("Starting batch")

            if not val_complete:
                segs, psds, temp, injs, gather_idxs, params = \
                    validation_samples.get_tensors(idxs, bank, cuts=True)

                logging.info("Batch inputs read")
                
                snr_prime, snr, rchisq = chisq_transform.get_max_snr_prime(
                    temp, segs, psds, params, gather_idxs=gather_idxs,
                    max_snr=True, training=False
                )

                val_snrs += [snr]
                val_rchisqs += [rchisq]
                val_injs += [injs]

            else:
                idxs = tf.convert_to_tensor(idxs)
                snr = tf.gather(val_snrs, idxs)
                rchisq = tf.gather(val_rchisqs, idxs)
                injs = tf.gather(val_injs, idxs)

                snr_prime = chisq_transform.get_snr_prime(snr, rchisq, training=False)

            batch_loss = loss_fn(snr_prime, snr, injs, training=False)
            val_loss += tf.reduce_sum(batch_loss)

            logging.info("Loss calculated")
            logging.info("Completed batch")

            inj_lgc = injs.numpy()
            trig_lgc = np.logical_not(inj_lgc)

            val_inj_count += np.sum(inj_lgc)
            val_trig_count += np.sum(trig_lgc)
            total_count = val_inj_count + val_trig_count

            val_inj_loss += np.sum(batch_loss.numpy()[inj_lgc])
            val_trig_loss += np.sum(batch_loss.numpy()[trig_lgc])

            val_snr_removed += np.sum(1 - (snr_prime / snr).numpy()[trig_lgc])
            val_inj_removed += np.sum(1 - (snr_prime / snr).numpy()[inj_lgc])

            if np.sum(trig_lgc):
                val_trig_snr_primes += [snr_prime.numpy()[trig_lgc]]
                val_trig_snrs += [snr.numpy()[trig_lgc]]
                val_trig_rchisq += [rchisq.numpy()[trig_lgc]]
            if np.sum(inj_lgc):
                val_inj_snr_primes += [snr_prime.numpy()[inj_lgc]]
                val_inj_snrs += [snr.numpy()[inj_lgc]]
                val_inj_rchisq += [rchisq.numpy()[inj_lgc]]

            if k == (val_nbatches - 1):
                end_str = '\n'
            else:
                end_str = '\r'
                
            print("Batch: {0:4d}/{1:4d}, ".format(k + 1, val_nbatches)
                  + "Av. Loss: {0:3.4f}, ".format(val_loss / total_count)
                  + "Av. Inj Loss: {0:3.4f}, ".format(val_inj_loss / max(val_inj_count, 1))
                  + "Av. Trig Loss: {0:3.4f}, ".format(val_trig_loss / max(val_trig_count, 1)),
                  end=end_str)

        val_losses += [val_loss / total_count]
        val_batches += [nbatch]

        val_inj_losses += [val_inj_loss / val_inj_count]
        val_trig_losses += [val_trig_loss / val_trig_count]

        val_snr_removeds += [val_snr_removed / val_trig_count]
        val_inj_removeds += [val_inj_removed / val_inj_count]

        if not val_complete:
            val_snrs = tf.concat(val_snrs, axis=0)
            val_rchisqs = tf.concat(val_rchisqs, axis=0)
            val_injs = tf.concat(val_injs, axis=0)
            val_complete = True

chisq_transform.to_file(
    args.output_file,
    group="model_epoch_0",
    append=False
)

inj_losses = np.array(inj_losses) / np.maximum(np.array(inj_count), 1)
trig_losses = np.array(trig_losses) / np.maximum(np.array(trig_count), 1)
snr_removed = np.array(snr_removed) / np.maximum(np.array(trig_count), 1)
inj_removed = np.array(inj_removed) / np.maximum(np.array(inj_count), 1)

if len(val_trig_snr_primes):
    val_trig_snr_primes = np.concatenate(val_trig_snr_primes, axis=0)
    val_trig_snrs = np.concatenate(val_trig_snrs, axis=0)
    val_trig_rchisq = np.concatenate(val_trig_rchisq, axis=0)
if len(val_inj_snr_primes):
    val_inj_snr_primes = np.concatenate(val_inj_snr_primes, axis=0)
    val_inj_snrs = np.concatenate(val_inj_snrs, axis=0)
    val_inj_rchisq = np.concatenate(val_inj_rchisq, axis=0)

with h5py.File(args.output_file, 'a') as f:
    f.attrs['epoch'] = 0
    _ = f.create_dataset('training_batch_epoch_0', data=np.array(batches) - batches[-1])
    _ = f.create_dataset('training_loss_epoch_0', data=np.array(losses))
    _ = f.create_dataset('training_inj_loss_epoch_0', data=inj_losses)
    _ = f.create_dataset('training_trig_loss_epoch_0', data=trig_losses)
    _ = f.create_dataset('training_trig_snr_removed_epoch_0', data=snr_removed)
    _ = f.create_dataset('training_inj_snr_removed_epoch_0', data=inj_removed)

    if args.validation_sample_file:
        _ = f.create_dataset('validation_batch_epoch_0',
                             data=np.array(val_batches) - val_batches[-1])
        _ = f.create_dataset('validation_loss_epoch_0',
                             data=np.array(val_losses))
        _ = f.create_dataset('validation_inj_loss_epoch_0',
                             data=np.array(val_inj_losses))
        _ = f.create_dataset('validation_trig_loss_epoch_0',
                            data=np.array(val_trig_losses))
        _ = f.create_dataset('validation_trig_snr_removed_epoch_0',
                             data=np.array(val_snr_removeds))
        _ = f.create_dataset('validation_inj_snr_removed_epoch_0',
                             data=np.array(val_inj_removeds))
        
    if len(val_trig_snr_primes):
        _ = f.create_dataset('validation_trig_snr_primes_epoch_0',
                             data=np.array(val_trig_snr_primes))
        _ = f.create_dataset('validation_trig_snrs_epoch_0',
                             data=np.array(val_trig_snrs))
        _ = f.create_dataset('validation_trig_rchisq_epoch_0',
                             data=np.array(val_trig_rchisq))
    if len(val_inj_snr_primes):
        _ = f.create_dataset('validation_inj_snr_primes_epoch_0',
                             data=np.array(val_inj_snr_primes))
        _ = f.create_dataset('validation_inj_snrs_epoch_0',
                             data=np.array(val_inj_snrs))
        _ = f.create_dataset('validation_inj_rchisq_epoch_0',
                             data=np.array(val_inj_rchisq))
