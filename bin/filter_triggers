#! /usr/bin/env python

import argparse
import logging
import h5py
from chisqnet.preprocessing import TriggerList, InjectionTriggers
from copy import deepcopy


parser = argparse.ArgumentParser()

# Gather inputs from search workflow used to select data for training
parser.add_argument("--trigger-files", nargs='+', required=True,
                    help="List of single detector trigger files used to "
                         "select sample times for training")
parser.add_argument("--injfind-file", required=False,
                    help="Injfind file used to select observable "
                         "injections for use in training")
parser.add_argument("--veto-files", nargs='+', required=True,
                    help='Segment files conatining the "closed_box" veto '
                         'used to remove foreground triggers')
parser.add_argument("--bank-file", required=True,
                    help="Template bank file used in search workflow")

# Gather output options
parser.add_argument("--output-file", required=True,
                    help="Output location for training sample times")

# Gather inputs for filtering triggers
parser.add_argument("--newsnr-cut", type=float, default=0,
                    help="Threshold for removing triggers below newsnr")
parser.add_argument("--newsnr-sg-cut", type=float, default=0,
                    help="Threshold for removing triggers below newsnr_sg")
parser.add_argument("--cluster-param",
                    help="Parameter to use when clustering triggers")
parser.add_argument("--cluster-window", type=float,
                    help="Window in seconds to use when clustering triggers")
parser.add_argument("--cluster-keep-top-n", type=int, default=1,
                    help="If greater than one, run clustering this many times, "
                         "removing previous triggers after each step")
parser.add_argument("--keep-n-triggers", type=int,
                    help="After all other clustering randomly select this many triggers")
parser.add_argument("--inj-ifar-cut", type=float, default=0.,
                    help="Threshold for removing injection below IFAR")

parser.add_argument("--snr-bins", type=float, nargs="+", required=True,
                    help="The boundaries in SNR to select triggers")
parser.add_argument("--count-per-bin", type=int, nargs="+", required=True,
                    help="The number of triggers to keep for each SNR bin")

# Gather additional options
parser.add_argument("--verbose", action='store_true')

args = parser.parse_args()

if args.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARNING
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

if len(args.count_per_bin) == 1:
    args.count_per_bin = args.count_per_bin * (len(args.snr_bins) - 1)

if (len(args.snr_bins) - 1) != len(args.count_per_bin):
    raise ValueError("--count-per-bin must be 1 smaller than --snr-bins or length 1")

logging.info("Reading triggers from files.")
if args.injfind_file is None:
    triggers = TriggerList(args.trigger_files)
else: 
    trigger_dict = {}
    for fp in args.trigger_files:
        with h5py.File(fp, 'r') as f:
            if len(f.keys()) > 1:
                raise ValueError("Each trigger file should only have 1 group with the ifo as key.")
            ifo = list(f.keys())[0]
        if ifo in trigger_dict.keys():
            raise ValueError("Multiple trigger files for {0}.".format(ifo))
        trigger_dict[ifo] = fp
    triggers = InjectionTriggers(args.injfind_file, trigger_dict,
                                 ifar_threshold=args.inj_ifar_cut)

triggers.apply_segments(args.veto_files, "closed_box", within=False)

logging.info("Triggers available:")
for k, v in triggers.nums.items():
    logging.info("{0}: {1}".format(k, v))
    
args.newsnr_cut = max(args.newsnr_cut, args.newsnr_sg_cut)

triggers.threshold_cut(args.snr_bins[0], 'snr')

if args.newsnr_cut:
    triggers.get_newsnr()
    triggers.threshold_cut(args.newsnr_cut, 'newsnr')

if args.newsnr_sg_cut:
    triggers.get_newsnr_sg()
    triggers.threshold_cut(args.newsnr_sg_cut, 'newsnr_sg')

logging.info("Triggers available after threshold cuts:")
for k, v in triggers.nums.items():
    logging.info("{0}: {1}".format(k, v))

if args.cluster_param and args.cluster_window:
    triggers.cluster_over_time(args.cluster_window, args.cluster_param,
                               keep_top=args.cluster_keep_top_n)

logging.info("Triggers available after clustering:")
for k, v in triggers.nums.items():
    logging.info("{0}: {1}".format(k, v))

keeps = None
for i in range(len(args.count_per_bin)):
    snr_min = args.snr_bins[i]
    snr_max = args.snr_bins[i + 1]
    count = args.count_per_bin[i]
    bin_triggers = deepcopy(triggers)
    bin_triggers.threshold_cut(snr_min, 'snr')
    bin_triggers.threshold_cut(snr_max, 'snr', above=False)
    bin_triggers.sample(count)
    logging.info("Triggers in SNR bin {0} -> {1}:".format(snr_min, snr_max))
    real_count = 0
    for k, v in bin_triggers.nums.items():
        logging.info("{0}: {1}".format(k, v))
        real_count += v
    logging.info("Triggers collected {0} out of {1} requested".format(real_count, count))
    if keeps is None:
        keeps = bin_triggers
    else:
        keeps.append(bin_triggers)

keeps.get_bank_params(args.bank_file)

logging.info("Saving triggers")
keeps.write_to_hdf(args.output_file)

logging.info("Done!")
