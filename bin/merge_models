#! /usr/bin/env python

import argparse
import logging
import h5py
import numpy as np
from chisqnet.preprocessing import DataCollector, AttributeCollector


parser = argparse.ArgumentParser()

# Gather inputs from preprocessing step
parser.add_argument("--model-files", nargs='+', required=True,
                    help="List of model files")

# Gather output options
parser.add_argument("--output-file", required=True,
                    help="Output location")

# Gather additional options
parser.add_argument("--verbose", action='store_true')

args = parser.parse_args()

if args.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARNING
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

logging.info("Reading and combining sample files")

file_attrs = AttributeCollector(check=False)
file_data = DataCollector()

epoch = 0
for fp in args.model_files:
    with h5py.File(fp, 'r') as f:
        file_attrs.get_root(f)
        f.visititems(file_attrs)
        f.visititems(file_data)
        epoch = max(epoch, f.attrs['epoch'])

file_data.concatenate_datasets()
batch_groups = {
    'training_batch': [],
    'training_loss': [],
    'training_inj_loss': [],
    'training_trig_loss': [],
    'training_snr_removed': [],
    'validation_batch': [],
    'validation_loss': [],
    'validation_inj_loss': [],
    'validation_trig_loss': [],
    'validation_snr_removed': []
}
for bg in batch_groups.keys():
    for i in range(epoch):
        batch_groups[bg] += [file_data.datasets[bg + '_epoch_{0}'.format(i + 1)][:]]
    batch_groups[bg] = np.concatenate(batch_groups[bg], axis=0)

with h5py.File(args.output_file, 'w') as f:
    
    for group, attrs in file_attrs.groups.items():
        if group not in f:
            g = f.create_group(group)
        else:
            g = f[group]

        for k, v in attrs.items():
            g.attrs[k] = v

    f.attrs['epoch'] = epoch

    for k, v in file_data.datasets.items():
        _ = f.create_dataset(k, data=v)

    for bg in batch_groups.keys():
        _ = f.create_dataset(bg, data=batch_groups[bg])

logging.info("Done!")
