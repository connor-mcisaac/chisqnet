#! /usr/bin/env python

import argparse, os
import logging, time
import h5py
import numpy as np
from chisqnet.preprocessing import TriggerList, add_params
from pycbc.workflow import SegFile
from chisqnet.strain import xml_to_segmentlistdict
from chisqnet.strain import StrainSegmentsCut
from pycbc import strain, psd, waveform, DYN_RANGE_FAC
from pycbc.types import zeros, float32, complex64


parser = argparse.ArgumentParser()

# Gather inputs
parser.add_argument("--trigger-file", required=True,
                    help="Trigger file to be used in training")

# Gather arguments for loading and preparing strain data
strain.insert_strain_option_group(parser)
StrainSegmentsCut.insert_segment_option_group(parser)
psd.insert_psd_option_group(parser)
parser.add_argument("--low-frequency-cutoff", type=float,
                  help="The low frequency cutoff to use for filtering (Hz)")
parser.add_argument("--snr-cut-width", default=0.1, type=float,
                    help="The width around each trigger to cut from the SNR timeseries")

# Gather output options
parser.add_argument("--output-file", required=True,
                    help="Name of the output file")

# Gather additional options
parser.add_argument("--ifo", required=True,
                    help="The IFO being analysed")
parser.add_argument("--chunk-num", default=1, type=int,
                    help="The number of samples to hold in a hdf chunk")
parser.add_argument("--extend-num", default=1, type=int,
                    help="The number of samples to load before extending the file")
parser.add_argument("--verbose", action='store_true')

args = parser.parse_args()

if args.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARNING
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

# Check option groups
strain.verify_strain_options(args, parser)
StrainSegmentsCut.verify_segment_options(args, parser)
psd.verify_psd_options(args, parser)

logging.info("Loading strain")
gwstrain = strain.from_cli(args, dyn_range_fac=DYN_RANGE_FAC,
                           precision='single')

samples = TriggerList.read_from_hdf(args.trigger_file)

delta_f = 1. / args.segment_length
tlen = int(args.segment_length * args.sample_rate)
flen = tlen // 2 + 1

path = os.path.dirname(args.output_file)
if path != '':
    if not os.path.exists(path) and path is not None:
        os.makedirs(path)

with h5py.File(args.output_file, 'w') as f:

    stildes = []
    psds = []
    cuts = []
    samps = []

    seg_samples = samples.get_time_cut(args.ifo,
                                       args.trig_start_time,
                                       args.trig_end_time)
    seg_times = seg_samples['end_time']
    trig_num = len(seg_samples)

    seg_samples = add_params(seg_samples, np.array([[args.ifo] * trig_num], dtype='U2'),
                             ['ifo'], ['U2'])

    logging.info("Segmenting strain")
    segs = StrainSegmentsCut.from_cli(args, gwstrain)
    segs.cut(seg_times, args.snr_cut_width)

    logging.info("Fourier transforming strain")
    stilde = segs.fourier_segments()

    logging.info("Calculating PSDs")
    psd.associate_psds_to_segments(args, stilde, gwstrain,
                                   segs.freq_len, segs.delta_f,
                                   args.low_frequency_cutoff,
                                   dyn_range_factor=DYN_RANGE_FAC,
                                   precision='single')

    seg_psds = [seg.psd for seg in stilde]

    logging.info("Selecting sample data")
    for i in range(trig_num):
        
        sidx = segs.sample_segments[i]
        cidx = segs.sample_slices[i]

        stildes.append(stilde[sidx].numpy())
        psds.append(seg_psds[sidx].numpy())
        cuts.append(np.array([cidx.start, cidx.stop]))
        samps.append(seg_samples[i])

        if len(stildes) > args.extend_num:
            logging.info("Writing to file")
            if "stilde" not in f.keys():
                stilde_group = f.create_dataset("stilde", (len(stildes), flen), dtype='c8',
                                                chunks=(args.chunk_num, flen), maxshape=(None, flen))
                psd_group = f.create_dataset("psd", (len(stildes), flen), dtype='f4',
                                             chunks=(args.chunk_num, flen), maxshape=(None, flen))
            else:
                stilde_group.resize(stilde_group.len() + len(stildes), axis=0)
                psd_group.resize(psd_group.len() + len(psds), axis=0)

            stilde_group[-len(stildes):, :] = np.stack(stildes)
            psd_group[-len(psds):, :] = np.stack(psds)

            stildes = []
            psds = []

    if len(stildes) > 0:
        logging.info("Writing to file")
        if "stilde" not in f.keys():
            stilde_group = f.create_dataset("stilde", (len(stildes), flen), dtype='c8',
                                            chunks=(args.chunk_num, flen), maxshape=(None, flen))
            psd_group = f.create_dataset("psd", (len(stildes), flen), dtype='f4',
                                         chunks=(args.chunk_num, flen), maxshape=(None, flen))
        else:
            stilde_group.resize(stilde_group.len() + len(stildes), axis=0)
            psd_group.resize(psd_group.len() + len(psds), axis=0)

        stilde_group[-len(stildes):, :] = np.stack(stildes)
        psd_group[-len(psds):, :] = np.stack(psds)

    logging.info("Writing cuts and samples")
    cuts = np.stack(cuts)
    samps = np.stack(samps)

    cut_group = f.create_dataset("cut", data=cuts)
    
    for p, d in zip(samples._params, samples._dtypes):
        data = samps[p][:]
        if d.startswith('U'):
            data = data.astype('S')
        _ = f.create_dataset(p, data=data)
    
    _ = f.create_dataset('ifo', data=samps['ifo'][:].astype('S'))
    f.attrs['flow'] = args.low_frequency_cutoff
    f.attrs['flen'] = flen
    f.attrs['delta_f'] = delta_f
    f.attrs['tlen'] = tlen
    f.attrs['sample_rate'] = args.sample_rate

    parameters = []
    for k in ['mass1', 'mass2', 'spin1z', 'spin2z',
              'template_duration', 'approximant']:
        if k in samps.dtype.names:
            parameters.append(k)
    f.attrs['parameters'] = parameters

logging.info("Done")
